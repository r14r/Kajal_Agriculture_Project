# Green Farming - Robots.txt
# This file tells search engines how to crawl the website

# Allow all robots
User-agent: *
Allow: /
Allow: /css/
Allow: /js/
Allow: /images/

# Disallow private areas (if any)
# Disallow: /admin/
# Disallow: /private/

# Sitemap location
Sitemap: http://example.com/sitemap.xml

# Crawl delay (optional - for slower servers)
# Crawl-delay: 1

# Specific rules for Googlebot
User-agent: Googlebot
Allow: /
Crawl-delay: 0

# Specific rules for Bingbot
User-agent: Bingbot
Allow: /
Crawl-delay: 1

# Block bad bots (optional)
User-agent: MJ12bot
Disallow: /

User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /
